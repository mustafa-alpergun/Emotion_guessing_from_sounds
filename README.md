Hello

In this project, I developed an end-to-end audio emotion recognition system that analyzes speech signals and classifies emotional states using machine learning.

Project Overview

ğŸ”¹ Model Architecture:
I implemented a Multi-Layer Perceptron (MLPClassifier) to classify emotions based on extracted acoustic features.

ğŸ”¹ Objective:
To automatically detect and classify emotions from .wav audio files using signal processing and supervised learning techniques.

Technical Pipeline

ğŸ”¹ Audio Feature Engineering:
Extracted high-level acoustic features using MFCC (Mel-Frequency Cepstral Coefficients), Chroma, and Mel Spectrogram representations via librosa.
These features were aggregated using mean pooling to form a compact numerical representation of each audio sample.

ğŸ”¹ Data Preprocessing:
Applied StandardScaler normalization to ensure stable and efficient convergence of the MLP model.

ğŸ”¹ Dataset Handling:
Structured dataset parsing with automatic emotion label extraction from file naming conventions.

ğŸ”¹ Model Training:
Split dataset into 80% training and 20% testing using stratified sampling to maintain class balance.
Trained the MLP model with adaptive learning rate and optimized hyperparameters.

ğŸ”¹ Evaluation:
Performance measured using:

Accuracy Score

Classification Report (Precision, Recall, F1-Score)

ğŸ”¹ Model Persistence:
Saved trained model and scaler objects using joblib for future inference or deployment.

Machine Learning Approach

Unlike deep learning-based CNN audio models, this system focuses on:

Signal processing-based feature extraction

Classical neural network classification (MLP)

Efficient and lightweight architecture suitable for structured ML pipelines

 Tech Stack

Python, NumPy, Librosa, Scikit-learn, Joblib, Logging

Feel free to review the architecture and share your thoughts or improvement suggestions.

Author: Mustafa AlpergÃ¼n

Merhaba

Bu projede, konuÅŸma verilerinden duygusal durumu analiz eden ve sÄ±nÄ±flandÄ±ran uÃ§tan uca bir Ses TabanlÄ± Duygu TanÄ±ma Sistemi geliÅŸtirdim.

Proje Ã–zeti

ğŸ”¹ Model Mimarisi:
Ses Ã¶zelliklerini kullanarak duygu sÄ±nÄ±flandÄ±rmasÄ± yapan bir Ã‡ok KatmanlÄ± AlgÄ±layÄ±cÄ± (MLPClassifier) modeli tasarladÄ±m.

ğŸ”¹ AmaÃ§:
.wav formatÄ±ndaki konuÅŸma kayÄ±tlarÄ±ndan duygusal ifadeleri otomatik olarak tespit etmek.

 Teknik SÃ¼reÃ§

ğŸ”¹ Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature Extraction):
Librosa kÃ¼tÃ¼phanesi ile:

MFCC

Chroma

Mel Spectrogram

Ã¶zellikleri Ã§Ä±karÄ±ldÄ± ve her ses dosyasÄ± iÃ§in sayÄ±sal Ã¶zellik vektÃ¶rleri oluÅŸturuldu.

ğŸ”¹ Veri Normalizasyonu:
MLP algoritmasÄ±nÄ±n saÄŸlÄ±klÄ± Ã§alÄ±ÅŸmasÄ± iÃ§in StandardScaler ile standardizasyon uygulandÄ±.

ğŸ”¹ Veri BÃ¶lme:
Veri seti %80 eÄŸitim, %20 test olacak ÅŸekilde dengeli biÃ§imde ayrÄ±ldÄ±.

ğŸ”¹ Model EÄŸitimi ve DeÄŸerlendirme:
Model doÄŸruluk oranÄ± ve detaylÄ± sÄ±nÄ±flandÄ±rma raporlarÄ± ile analiz edildi.

ğŸ”¹ Model Kaydetme:
EÄŸitilmiÅŸ model ve Ã¶lÃ§ekleyici joblib kullanÄ±larak diske kaydedildi.

 KullanÄ±lan Teknolojiler

Python, NumPy, Librosa, Scikit-learn, Joblib

Kod yapÄ±sÄ±nÄ± incelemek ve geliÅŸtirme Ã¶nerilerinizi paylaÅŸmak isterseniz geri bildirimlerinizi memnuniyetle karÅŸÄ±larÄ±m.

ğŸ‘‡ Yazar: Mustafa AlpergÃ¼n
